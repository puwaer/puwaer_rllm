torch,flash_attn
(test_rllm) [j26001@mg0004 vllm]$ pip list
Package           Version
----------------- -----------
einops            0.8.1
filelock          3.13.1
flash_attn        2.7.4.post1
fsspec            2024.6.1
Jinja2            3.1.4
MarkupSafe        2.1.5
mpmath            1.3.0
networkx          3.3
ninja             1.11.1.4
numpy             2.1.2
packaging         25.0
pillow            11.0.0
pip               25.1
pybind11          2.13.6
setuptools        80.0.1
sympy             1.13.1
torch             2.5.1
torchaudio        2.5.1
torchvision       0.20.1
typing_extensions 4.12.2
wheel             0.45.1



torch,flash_attn,vllm
